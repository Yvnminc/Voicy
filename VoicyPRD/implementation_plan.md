# Implementation plan

## Phase 1: Environment Setup

1. **Prevalidation:** Check if the current directory is already a project (e.g., check for package.json) to avoid re-initialization. (Project Overview)
2. **Install Node.js:** Ensure Node.js v20.2.1 is installed. If not, install Node.js v20.2.1. (Tech Stack: Core Tools)
3. **Validate Node.js Installation:** Run `node -v` to confirm version is v20.2.1. (Tech Stack: Core Tools)
4. **Initialize Next.js Project:** Create a new Next.js project with Next.js 14 (exact version) using:
   ```bash
   npx create-next-app@14 your-voice-memo-app --typescript
   ```
   Note: Next.js 14 is used as it is better suited with current AI coding tools and LLM models. (Tech Stack: Frontend)
5. **Install Tailwind CSS and Shadcn UI:** Follow their installation guides in the project root. Create configuration files as required:
   - Install Tailwind CSS:
     ```bash
     npm install -D tailwindcss postcss autoprefixer
     npx tailwindcss init -p
     ```
   - Install Shadcn UI (per Shadcn UI docs). (Tech Stack: Frontend)
6. **Install Dependencies for TypeScript:** Ensure TypeScript is configured properly (check tsconfig.json) in the project root. (Tech Stack: Frontend)
7. **Initialize Git Repository:** Run `git init` in the project root if not already present. (Development Tools)
8. **Set Up Supabase:** Since Supabase is used as the backend for storage, instruct the user to visit [Supabase MCP Connection Guide](https://supabase.com/docs/guides/getting-started/mcp#connect-to-supabase-using-mcp) to obtain the connection string. (Tech Stack: Backend & Data Management)
9. **Configure Supabase in Cursor (if using Cursor tool):**
   - Create a `.cursor` directory in the project root if it doesn't exist.
   - Create and open a file at `.cursor/mcp.json`.
   - Add the following configuration based on your operating system:
     - For macOS:
       ```json
       { "mcpServers": { "supabase": { "command": "npx", "args": ["-y", "@modelcontextprotocol/server-postgres", "<connection-string>"] } } }
       ```
     - For Windows:
       ```json
       { "mcpServers": { "supabase": { "command": "cmd", "args": ["/c", "npx", "-y", "@modelcontextprotocol/server-postgres", "<connection-string>"] } } }
       ```
   - Replace `<connection-string>` with your own connection string.
   - Navigate to **Settings/MCP** in Cursor to verify the green active status. (Tech Stack: Backend & Data Management)
10. **Configure Supabase in Windsurf (if using Windsurf tool):**
    - Open the Cascade assistant.
    - Tap on the hammer (MCP) icon and choose **Configure**.
    - Add the same configuration as in step 9, using the appropriate OS snippet.
    - Save the configuration file and reload by tapping **Refresh** in the Cascade assistant. (Tech Stack: Backend & Data Management)

## Phase 2: Frontend Development

11. **Setup Project Structure:** Validate /src and /pages directories exist in the Next.js project. (Project Overview)
12. **Create Home Page:** Create `/pages/index.tsx` to serve as the landing page with a simple UI inspired by Appleâ€™s Voice Memos and ChatGPT. (Design: UI)
13. **Implement Navigation Layout:** Create a layout component (e.g., `/src/components/Layout.tsx`) to include a sidebar for folder navigation and main area for voice memo functionalities. (Design: UI)
14. **Design Header and Footer Components:** Create `/src/components/Header.tsx` and `/src/components/Footer.tsx` for branding and navigation. (Design: UI)
15. **Develop Voice Recorder Component:** Create `/src/components/VoiceRecorder.tsx` that:
    - Uses the Web Audio API for live recording.
    - Integrates the Google API for real-time speech-to-text transcription.
    - Displays transcribed text live.
    (Core Features: Voice-to-Text)
16. **Implement File Upload Component:** Create `/src/components/AudioUploader.tsx` to allow users to upload pre-recorded MP3 files for transcription. (Core Features: Voice-to-Text)
17. **Build Folder System Component:** Create `/src/components/FolderManager.tsx` for creating, listing, and deleting folders to organize recordings. (Core Features: Folder System)
18. **Develop AI Summarization Component:** Create `/src/components/AISummarizer.tsx` that:
    - Sends transcribed text to GPT 4o API for meeting summarization.
    - Displays the summarized text.
    (Core Features: AI Integration)
19. **Build Chat Interface Component:** Create `/src/components/ChatInterface.tsx` allowing interactive chat queries regarding past recordings via GPT 4o. (Core Features: AI Integration)
20. **Implement Audio Download Component:** Create `/src/components/AudioDownloader.tsx` to allow users to download audio files in MP3 format. (Core Features: Audio Management)
21. **Create Language Settings Component:** Create `/src/components/LanguageSettings.tsx` for selecting transcription languages. (Core Features: Settings)
22. **Integrate Shadcn UI Components:** Replace base UI elements with Shadcn UI components where applicable. (Tech Stack: Frontend)
23. **Apply Tailwind CSS Styling:** Configure Tailwind CSS in `/styles/globals.css` to use the black, red, and white color scheme as per design. (Design: UI)
24. **Validation:** Test each UI component using Next.js development mode by running `npm run dev` and ensuring responsiveness and basic functionality. (Frontend Development)

## Phase 3: Backend Development

25. **Setup API Routes:** In the `/pages/api` directory, create necessary API endpoints.
26. **Create Transcription Endpoint:** Create `/pages/api/transcribe.ts` to handle:
    - Receiving audio data (both recorded and uploaded).
    - Interacting with the Google API to perform real-time or batch transcription.
    (Core Features: Voice-to-Text)
27. **Implement Google API Integration:** Within `/pages/api/transcribe.ts`, add logic to stream audio data to the Google API and return transcription results. (Core Features: Voice-to-Text)
28. **Create Folder Management Endpoints:** Develop endpoints (e.g., `/pages/api/folders.ts`) to handle creation, deletion, and listing of folders. (Core Features: Folder System)
29. **Develop AI Summarization Endpoint:** Create `/pages/api/summarize.ts` to:
    - Accept transcribed text.
    - Call the GPT 4o API for summarization.
    (Core Features: AI Integration)
30. **Implement Chat Conversation Endpoint:** Create `/pages/api/chat.ts` to interface with the GPT 4o API for interactive Q&A based on previous recordings.
    (Core Features: AI Integration)
31. **Create Audio Storage Endpoint:** Although Supabase will manage storage, create an endpoint (e.g., `/pages/api/audio.ts`) to handle metadata recording for uploaded audio files. (Core Features: Audio Management)
32. **Integrate Supabase Storage:** Use the Supabase client library in the backend API endpoints to store and retrieve audio files and manage folder data. (Tech Stack: Backend & Data Management)
33. **Validation:** Test each API endpoint using Postman or curl commands to ensure they return the expected JSON responses. (Backend Development)

## Phase 4: Integration

34. **Connect Frontend to Transcription API:** In `/src/components/VoiceRecorder.tsx` and `/src/components/AudioUploader.tsx`, add fetch or axios calls to `/api/transcribe` to send audio data and receive transcriptions. (Core Features: Voice-to-Text)
35. **Integrate Folder Management:** Connect the FolderManager component with `/api/folders` to dynamically create, list, and delete folders. (Core Features: Folder System)
36. **Integrate AI Summarization:** Connect the AISummarizer component to `/api/summarize` for processing transcriptions via GPT 4o. (Core Features: AI Integration)
37. **Integrate Chat Interface:** Wire up the ChatInterface component to `/api/chat` to send queries and display responses from GPT 4o. (Core Features: AI Integration)
38. **Connect Audio Downloading:** Ensure the AudioDownloader component fetches the correct audio file URLs from the Supabase storage connections. (Core Features: Audio Management)
39. **Connect Language Settings:** Ensure changes in language settings (through LanguageSettings component) are reflected in the transcription API request parameters when calling Google API. (Core Features: Settings)
40. **Validation:** Run integration tests by simulating user interactions to ensure smooth communication between frontend components and API endpoints. (Integration)

## Phase 5: Deployment

41. **Prepare Deployment Configuration:** Verify all environment variables and configuration files for Supabase, Google API, and GPT 4o are set correctly in a `.env.local` file at the project root. (Project Overview)
42. **Set Up Vercel Deployment:** (or your chosen hosting) Connect the GitHub repository to Vercel for deployment of the Next.js app. (Tech Stack: Frontend)
43. **Configure Build Settings:** Ensure the build settings in Vercel use Node.js v20.2.1 and Next.js 14. (Tech Stack: Frontend)
44. **Deploy to Vercel:** Initiate the deployment from Vercel. (Deployment)
45. **Validation:** After deployment, verify that all API endpoints are working by testing them via browser or Postman.

## Additional Considerations & Validations

46. **Monitor API Rate Limits:** Implement logging in the transcription endpoint to monitor Google API rate limits and latency issues. (Core Features: Voice-to-Text)
47. **Handle Supabase Connectivity Issues:** Add basic retry logic or error messaging within the Supabase API usage so users are informed of connectivity issues. (Tech Stack: Backend & Data Management)
48. **Ensure MP3 Format Compliance:** Validate file formats for uploads in `/src/components/AudioUploader.tsx` and enforce MP3 only. (Core Features: Audio Management)
49. **UI/UX Responsiveness:** Use responsive design principles with Tailwind CSS to ensure a great single-user experience on both desktop and mobile. (Design: UI)
50. **End-to-End Testing:** Run thorough tests across the entire application (recording, transcribing, summarizing, chatting, folder management, audio download) to ensure all features work as intended before a full production launch. (Core Features: All)

This completes the step-by-step implementation plan for the voice memo web app. Follow these steps carefully to build a comprehensive, integrated application as specified in the project details.